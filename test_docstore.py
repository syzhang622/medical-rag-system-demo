#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éªŒè¯ docstore.json æ–‡ä»¶å†…å®¹
"""

import json
import os

def check_docstore():
    """æ£€æŸ¥ docstore.json æ–‡ä»¶å†…å®¹"""
    docstore_path = "data/faiss_index/sentence-transformers_all-MiniLM-L6-v2_cs512_co50/docstore.json"
    
    if not os.path.exists(docstore_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {docstore_path}")
        return
    
    try:
        # è¯»å– docstore.json æ–‡ä»¶
        with open(docstore_path, 'r', encoding='utf-8') as f:
            docstore_content = json.load(f)
        
        print("âœ… æˆåŠŸè¯»å– docstore.json æ–‡ä»¶")
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(docstore_path)} bytes")
        
        # æ£€æŸ¥æ–‡æ¡£å­˜å‚¨ç»“æ„
        docstore_data = docstore_content.get('docstore', {})
        docs = docstore_data.get('docs', {})
        
        print(f"ğŸ“Š æ–‡æ¡£å­˜å‚¨ä¸­çš„èŠ‚ç‚¹æ•°é‡: {len(docs)}")
        
        if len(docs) == 0:
            print("âŒ è­¦å‘Š: æ–‡æ¡£å­˜å‚¨ä¸­æ²¡æœ‰èŠ‚ç‚¹!")
            return
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªèŠ‚ç‚¹çš„æ–‡æœ¬ç‰‡æ®µ
        print("\nğŸ“ å‰å‡ ä¸ªèŠ‚ç‚¹çš„æ–‡æœ¬ç‰‡æ®µ:")
        for i, (node_id, node_data) in enumerate(list(docs.items())[:3]):
            text = node_data.get('_data_', {}).get('text', '')
            text_preview = text[:100] + '...' if len(text) > 100 else text
            print(f"èŠ‚ç‚¹{i+1} (ID: {node_id[:8]}...): {text_preview}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬å†…å®¹
        has_text = any(
            node_data.get('_data_', {}).get('text', '') 
            for node_data in docs.values()
        )
        
        if has_text:
            print("âœ… æ–‡æ¡£å­˜å‚¨åŒ…å«æ–‡æœ¬å†…å®¹")
        else:
            print("âŒ è­¦å‘Š: æ–‡æ¡£å­˜å‚¨ä¸­æ²¡æœ‰æ–‡æœ¬å†…å®¹!")
            
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    check_docstore()
