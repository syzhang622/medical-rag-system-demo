#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸€é”®è¯„ä¼°æ‰€æœ‰æ¨¡å¼ - è‡ªåŠ¨è¿è¡Œå®Œæ•´è¯„ä¼°

ç”¨æ³•ï¼š
    python -m scripts.run_eval_all
    
åŠŸèƒ½ï¼š
1. ä¾æ¬¡è¿è¡Œ baseã€hydeã€hybrid ä¸‰ç§æ¨¡å¼çš„è¯„ä¼°
2. å¯é€‰ï¼šè¿è¡Œå¸¦é‡æ’çš„è¯„ä¼°
3. ç”Ÿæˆæ±‡æ€»å¯¹æ¯”æŠ¥å‘Š
"""

import os
import sys
import subprocess
import pandas as pd
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

def run_evaluation(mode: str, k: int = 3, rerank: bool = False) -> str:
    """è¿è¡Œå•ä¸ªè¯„ä¼°ä»»åŠ¡
    
    Args:
        mode: è¯„ä¼°æ¨¡å¼ (base/hyde/hybrid)
        k: Top-Kå€¼
        rerank: æ˜¯å¦å¯ç”¨é‡æ’
        
    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # æ„å»ºè¾“å‡ºæ–‡ä»¶å
    suffix = f"_rerank" if rerank else ""
    output_file = f"data/eval_results_{mode}{suffix}.csv"
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        sys.executable, "-m", "scripts.eval",
        "--k", str(k),
        "--export", output_file
    ]
    
    # æ·»åŠ æ¨¡å¼å‚æ•°
    if mode == "hyde":
        cmd.append("--hyde")
    elif mode == "hybrid":
        cmd.append("--hybrid")
    
    # æ·»åŠ é‡æ’å‚æ•°
    if rerank:
        cmd.append("--rerank")
    
    # æ‰§è¡Œè¯„ä¼°
    mode_name = f"{mode.upper()}" + (" + Rerank" if rerank else "")
    print(f"\n{'='*60}")
    print(f"ğŸ”„ è¿è¡Œè¯„ä¼°: {mode_name}")
    print(f"{'='*60}")
    print(f"å‘½ä»¤: {' '.join(cmd)}")
    print()
    
    try:
        result = subprocess.run(cmd, check=True, capture_output=False, text=True)
        print(f"âœ… {mode_name} è¯„ä¼°å®Œæˆ")
        print(f"ğŸ“„ ç»“æœä¿å­˜è‡³: {output_file}")
        return output_file
    except subprocess.CalledProcessError as e:
        print(f"âŒ {mode_name} è¯„ä¼°å¤±è´¥: {e}")
        return None
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº† {mode_name} è¯„ä¼°")
        raise


def load_and_summarize(file_path: str) -> dict:
    """åŠ è½½è¯„ä¼°ç»“æœå¹¶è®¡ç®—æ±‡æ€»æŒ‡æ ‡
    
    Args:
        file_path: CSVæ–‡ä»¶è·¯å¾„
        
    Returns:
        æ±‡æ€»æŒ‡æ ‡å­—å…¸
    """
    if not os.path.exists(file_path):
        return None
        
    df = pd.read_csv(file_path)
    
    return {
        "file": file_path,
        "hit_rate": df["hit_at_k"].mean() * 100,  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        "keyword_coverage": df["keyword_coverage"].mean() * 100,
        "best_rank_avg": df["citation_best_rank"].mean(),
        "num_questions": len(df)
    }


def print_comparison_table(results: dict):
    """æ‰“å°å¯¹æ¯”è¡¨æ ¼
    
    Args:
        results: å„æ¨¡å¼çš„è¯„ä¼°ç»“æœ
    """
    print(f"\n{'='*80}")
    print("ğŸ“Š è¯„ä¼°ç»“æœæ±‡æ€»å¯¹æ¯”")
    print(f"{'='*80}\n")
    
    # è¡¨å¤´
    print(f"{'æ¨¡å¼':<20} {'Hit@K':<12} {'å…³é”®è¯è¦†ç›–':<12} {'å¹³å‡æœ€ä½³æ’å':<12} {'é—®é¢˜æ•°':<8}")
    print("-" * 80)
    
    # æ•°æ®è¡Œ
    for mode_name, summary in results.items():
        if summary:
            print(f"{mode_name:<20} "
                  f"{summary['hit_rate']:>8.1f}%    "
                  f"{summary['keyword_coverage']:>8.1f}%    "
                  f"{summary['best_rank_avg']:>11.2f}     "
                  f"{summary['num_questions']:>6}")
    
    print("-" * 80)
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å¼
    valid_results = {k: v for k, v in results.items() if v is not None}
    if valid_results:
        best_hit = max(valid_results.items(), key=lambda x: x[1]['hit_rate'])
        best_coverage = max(valid_results.items(), key=lambda x: x[1]['keyword_coverage'])
        
        print(f"\nğŸ† æœ€ä½³å‘½ä¸­ç‡: {best_hit[0]} ({best_hit[1]['hit_rate']:.1f}%)")
        print(f"ğŸ† æœ€ä½³å…³é”®è¯è¦†ç›–: {best_coverage[0]} ({best_coverage[1]['keyword_coverage']:.1f}%)")
    
    print()


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸš€ RAGç³»ç»Ÿå®Œæ•´è¯„ä¼°")
    print("="*80)
    print()
    print("ğŸ“‹ è¯„ä¼°è®¡åˆ’:")
    print("  1. Base (åŸºçº¿æ£€ç´¢)")
    print("  2. HyDE (å‡è®¾ç­”æ¡ˆæ‰©å±•)")
    print("  3. Hybrid (æ··åˆæ£€ç´¢)")
    print()
    
    # è¯¢é—®æ˜¯å¦åŒ…å«é‡æ’è¯„ä¼°
    include_rerank = input("æ˜¯å¦åŒ…å«é‡æ’(Rerank)è¯„ä¼°? (y/n, é»˜è®¤n): ").strip().lower()
    include_rerank = include_rerank == 'y'
    
    if include_rerank:
        print("âœ… å°†è¿è¡Œ 6 ä¸ªè¯„ä¼°ä»»åŠ¡ï¼ˆ3ç§æ¨¡å¼ Ã— 2ç§é…ç½®ï¼‰")
    else:
        print("âœ… å°†è¿è¡Œ 3 ä¸ªè¯„ä¼°ä»»åŠ¡")
    
    print()
    input("æŒ‰ Enter å¼€å§‹è¯„ä¼°...")
    
    # è¿è¡Œè¯„ä¼°
    results = {}
    
    try:
        # åŸºç¡€è¯„ä¼°
        modes = ["base", "hyde", "hybrid"]
        for mode in modes:
            output_file = run_evaluation(mode, k=3, rerank=False)
            if output_file:
                results[mode.upper()] = load_and_summarize(output_file)
        
        # é‡æ’è¯„ä¼°ï¼ˆå¯é€‰ï¼‰
        if include_rerank:
            for mode in modes:
                output_file = run_evaluation(mode, k=3, rerank=True)
                if output_file:
                    results[f"{mode.upper()} + Rerank"] = load_and_summarize(output_file)
        
        # æ‰“å°å¯¹æ¯”è¡¨æ ¼
        print_comparison_table(results)
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_file = "data/eval_summary.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("RAGç³»ç»Ÿè¯„ä¼°ç»“æœæ±‡æ€»\n")
            f.write("="*80 + "\n\n")
            for mode_name, summary in results.items():
                if summary:
                    f.write(f"{mode_name}:\n")
                    f.write(f"  - Hit@K: {summary['hit_rate']:.1f}%\n")
                    f.write(f"  - å…³é”®è¯è¦†ç›–: {summary['keyword_coverage']:.1f}%\n")
                    f.write(f"  - å¹³å‡æœ€ä½³æ’å: {summary['best_rank_avg']:.2f}\n")
                    f.write(f"  - é—®é¢˜æ•°: {summary['num_questions']}\n\n")
        
        print(f"ğŸ“„ æ±‡æ€»ç»“æœå·²ä¿å­˜è‡³: {summary_file}")
        print("\nâœ… æ‰€æœ‰è¯„ä¼°ä»»åŠ¡å®Œæˆï¼")
        print(f"\nğŸ’¡ æç¤º: æŸ¥çœ‹ docs/EVALUATION_REPORT.md äº†è§£è¯¦ç»†åˆ†æ")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  è¯„ä¼°è¢«ç”¨æˆ·ä¸­æ–­")
        print("å·²å®Œæˆçš„è¯„ä¼°ç»“æœå·²ä¿å­˜")
        sys.exit(1)


if __name__ == "__main__":
    main()

