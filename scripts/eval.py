# -*- coding: utf-8 -*-
"""
é˜¶æ®µäºŒ - ç¬¬ä¸€æ­¥ï¼šæ£€ç´¢ä¾§è¯„ä¼°è„šæœ¬

ğŸ¯ è¿™ä¸ªè„šæœ¬åšä»€ä¹ˆï¼Ÿ
- æµ‹è¯•æˆ‘ä»¬çš„æ£€ç´¢ç³»ç»Ÿæ˜¯å¦èƒ½æŠŠ"æ­£ç¡®ç­”æ¡ˆ"æ‰¾å‡ºæ¥
- ä¸è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆï¼Œåªè¯„ä¼°"æ£€ç´¢"è¿™ä¸€æ­¥çš„æ•ˆæœ

ğŸ“Š è¯„ä¼°æŒ‡æ ‡ï¼š
1. Hit@Kï¼šæ£€ç´¢å‡ºçš„å‰Kä¸ªç‰‡æ®µä¸­ï¼Œæ˜¯å¦åŒ…å«æˆ‘ä»¬æœŸæœ›çš„å…³é”®è¯ï¼Ÿ
   - ä¾‹å¦‚ï¼šé—®"æ„Ÿå†’ç—‡çŠ¶"ï¼ŒæœŸæœ›æ‰¾åˆ°"å‘çƒ­ã€å’³å—½"
   - å¦‚æœå‰3ä¸ªç‰‡æ®µä¸­æœ‰ä»»ä½•ä¸€ä¸ªåŒ…å«è¿™äº›è¯ï¼Œå°±ç®—å‘½ä¸­
   
2. å…³é”®è¯è¦†ç›–ç‡ï¼šæ£€ç´¢å‡ºçš„ç‰‡æ®µä¸­ï¼Œè¦†ç›–äº†å¤šå°‘ä¸ªæœŸæœ›å…³é”®è¯ï¼Ÿ
   - ä¾‹å¦‚ï¼šæœŸæœ›4ä¸ªå…³é”®è¯ï¼Œæ‰¾åˆ°äº†3ä¸ªï¼Œè¦†ç›–ç‡=75%

ğŸ”§ æ€ä¹ˆç”¨ï¼Ÿ
python scripts/eval.py --k 3 --export results.csv
python scripts/eval.py --k 3 --rerank --export results_rerank.csv

ğŸ’¡ ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ
- å¦‚æœæ£€ç´¢éƒ½æ‰¾ä¸åˆ°æ­£ç¡®ç­”æ¡ˆï¼ŒLLMå†å¼ºä¹Ÿæ²¡ç”¨
- é€šè¿‡å¯¹æ¯”ä¸åŒå‚æ•°ï¼ˆKå€¼ã€æ˜¯å¦é‡æ’ï¼‰ï¼Œæ‰¾åˆ°æœ€ä½³é…ç½®
"""

import os
import sys
import csv
import argparse
from typing import Dict, List, Tuple, Optional
import statistics

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from scripts.config import Config
from core.retrieval import RetrievalService
from core.hyde import HyDERetriever


def normalize(s: str) -> str:
    """
    ğŸ”§ æ–‡æœ¬æ ‡å‡†åŒ–å‡½æ•°
    ä½œç”¨ï¼šæŠŠæ–‡æœ¬è½¬æˆå°å†™ï¼Œå»æ‰é¦–å°¾ç©ºæ ¼
    ä¸ºä»€ä¹ˆéœ€è¦ï¼šè®©å…³é”®è¯åŒ¹é…ä¸åŒºåˆ†å¤§å°å†™ï¼Œé¿å…ç©ºæ ¼å¯¼è‡´çš„åŒ¹é…å¤±è´¥
    ä¾‹å¦‚ï¼š"ç—‡çŠ¶" èƒ½åŒ¹é… "ä¸»è¦ç—‡çŠ¶åŒ…æ‹¬..."
    """
    return (s or "").strip().lower()


def keyword_presence_in_text(text: str, keywords: List[str]) -> Dict[str, bool]:
    """
    ğŸ” æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨æ–‡æœ¬ä¸­å‡ºç°
    
    è¾“å…¥ï¼š
    - text: è¦æœç´¢çš„æ–‡æœ¬ï¼ˆæ¯”å¦‚æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µï¼‰
    - keywords: æœŸæœ›æ‰¾åˆ°çš„å…³é”®è¯åˆ—è¡¨ï¼ˆæ¯”å¦‚["ç—‡çŠ¶", "å‘çƒ­"]ï¼‰
    
    è¾“å‡ºï¼š
    - å­—å…¸ï¼š{å…³é”®è¯: æ˜¯å¦å‡ºç°}
    ä¾‹å¦‚ï¼š{"ç—‡çŠ¶": True, "å‘çƒ­": False, "å¹¶å‘ç—‡": True}
    
    å·¥ä½œåŸç†ï¼š
    1. æŠŠæ–‡æœ¬å’Œå…³é”®è¯éƒ½è½¬æˆå°å†™ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    2. é€ä¸ªæ£€æŸ¥æ¯ä¸ªå…³é”®è¯æ˜¯å¦åœ¨æ–‡æœ¬ä¸­å‡ºç°
    3. è¿”å›æ¯ä¸ªå…³é”®è¯çš„åŒ¹é…ç»“æœ
    """
    text_n = normalize(text)  # æ ‡å‡†åŒ–æ–‡æœ¬
    presence: Dict[str, bool] = {}
    
    for kw in keywords:
        kwn = normalize(kw)  # æ ‡å‡†åŒ–å…³é”®è¯
        # æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨æ–‡æœ¬ä¸­ï¼ˆå¦‚æœä¸¤è€…éƒ½ä¸ä¸ºç©ºï¼‰
        presence[kw] = (kwn in text_n) if (kwn and text_n) else False
    
    return presence


def evaluate_single_question(
    svc: RetrievalService,
    hyde: Optional[HyDERetriever],
    question: str,
    expected_keywords: List[str],
    top_k: int,
    enable_rerank: bool,
    use_hyde: bool,
    use_hybrid: bool,
) -> Dict[str, object]:
    """
    ğŸ“Š å¯¹å•ä¸ªé—®é¢˜è¿›è¡Œå®Œæ•´çš„æ£€ç´¢ä¾§è¯„ä¼°
    
    è¾“å…¥ï¼š
    - svc: æ£€ç´¢æœåŠ¡ï¼ˆå·²ç»åŠ è½½å¥½ç´¢å¼•ï¼‰
    - question: è¦æµ‹è¯•çš„é—®é¢˜ï¼ˆæ¯”å¦‚"æ„Ÿå†’å’Œæµæ„Ÿæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"ï¼‰
    - expected_keywords: æœŸæœ›æ‰¾åˆ°çš„å…³é”®è¯ï¼ˆæ¯”å¦‚["ç—‡çŠ¶", "å‘çƒ­", "å¹¶å‘ç—‡"]ï¼‰
    - top_k: æ£€ç´¢å‰Kä¸ªç‰‡æ®µï¼ˆæ¯”å¦‚3ï¼‰
    - enable_rerank: æ˜¯å¦å¯ç”¨é‡æ’
    
    è¾“å‡ºï¼šè¯„ä¼°ç»“æœå­—å…¸ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæŒ‡æ ‡
    
    ğŸ¯ ä¸¤ä¸ªæ ¸å¿ƒæŒ‡æ ‡ï¼š
    1. hit_at_k: æ£€ç´¢æ˜¯å¦æˆåŠŸï¼Ÿ
       - æ£€æŸ¥å‰Kä¸ªç‰‡æ®µä¸­ï¼Œæ˜¯å¦æœ‰ä»»ä½•ä¸€ä¸ªåŒ…å«æœŸæœ›çš„å…³é”®è¯
       - 1è¡¨ç¤ºæˆåŠŸï¼Œ0è¡¨ç¤ºå¤±è´¥
       
    2. keyword_coverage: å…³é”®è¯è¦†ç›–ç‡ï¼Ÿ
       - æŠŠæ‰€æœ‰æ£€ç´¢åˆ°çš„ç‰‡æ®µåˆå¹¶ï¼Œçœ‹è¦†ç›–äº†å¤šå°‘ä¸ªæœŸæœ›å…³é”®è¯
       - 0.75è¡¨ç¤ºè¦†ç›–äº†75%çš„å…³é”®è¯
    """
    # æ­¥éª¤1ï¼šæ‰§è¡Œæ£€ç´¢ï¼Œè·å–å‰Kä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
    if use_hybrid and hyde is not None:
        results = hyde.retrieve_hybrid(question=question, top_k=top_k, enable_rerank=enable_rerank)
        mode = "hybrid"
    elif use_hyde and hyde is not None:
        results = hyde.retrieve_with_hyde(question=question, top_k=top_k, enable_rerank=enable_rerank)
        mode = "hyde"
    else:
        results = svc.retrieve(query=question, top_k=top_k, enable_rerank=enable_rerank)
        mode = "base"
    print(f"    æ£€ç´¢åˆ° {len(results)} ä¸ªç‰‡æ®µ")

    # æ­¥éª¤2ï¼šè®¡ç®—å…³é”®è¯è¦†ç›–ç‡
    # æŠŠæ‰€æœ‰æ£€ç´¢åˆ°çš„ç‰‡æ®µæ–‡æœ¬åˆå¹¶æˆä¸€ä¸ªé•¿æ–‡æœ¬
    concatenated = "\n".join([r.text or "" for r in results])
    # æ£€æŸ¥åˆå¹¶åçš„æ–‡æœ¬ä¸­åŒ…å«äº†å“ªäº›æœŸæœ›å…³é”®è¯
    presence_union = keyword_presence_in_text(concatenated, expected_keywords)

    # ç»Ÿè®¡å‘½ä¸­çš„å…³é”®è¯æ•°é‡
    num_present = sum(1 for v in presence_union.values() if v)
    total = max(1, len(expected_keywords))  # é¿å…é™¤é›¶
    keyword_coverage = num_present / total

    # æ­¥éª¤3ï¼šè®¡ç®—Hit@K ä¸ è¢«å¼•ç”¨ç‰‡æ®µï¼ˆä»£ç†ï¼‰åæ¬¡
    # æ£€æŸ¥å‰Kä¸ªç‰‡æ®µä¸­ï¼Œæ˜¯å¦æœ‰ä»»ä½•ä¸€ä¸ªç‰‡æ®µåŒ…å«æœŸæœ›å…³é”®è¯
    hit_at_k = False
    best_rank: int = 0  # 1-basedï¼Œ0 è¡¨ç¤ºæœªæ‰¾åˆ°
    for r in results:
        p = keyword_presence_in_text(r.text or "", expected_keywords)
        if any(p.values()):  # å¦‚æœè¿™ä¸ªç‰‡æ®µåŒ…å«ä»»ä½•æœŸæœ›å…³é”®è¯
            hit_at_k = True
            if best_rank == 0:
                best_rank = results.index(r) + 1

    # æ­¥éª¤4ï¼šæ•´ç†ç»“æœ
    present_keywords = [kw for kw, ok in presence_union.items() if ok]

    return {
        "question": question,
        "top_k": top_k,
        "enable_rerank": enable_rerank,
        "mode": mode,
        "hit_at_k": int(hit_at_k),  # 1æˆ–0
        "keyword_coverage": round(keyword_coverage, 4),  # 0-1ä¹‹é—´çš„å°æ•°
        "num_present": num_present,  # å‘½ä¸­çš„å…³é”®è¯æ•°é‡
        "num_expected": total,  # æœŸæœ›çš„å…³é”®è¯æ€»æ•°
        "present_keywords": ",".join(present_keywords),  # å‘½ä¸­çš„å…³é”®è¯åˆ—è¡¨
        "citation_in_topk": int(best_rank > 0),
        "citation_best_rank": (best_rank or None),
    }


def export_csv(rows: List[Dict[str, object]], out_path: str) -> None:
    """
    ğŸ’¾ å¯¼å‡ºè¯„ä¼°ç»“æœåˆ°CSVæ–‡ä»¶
    
    ä½œç”¨ï¼šæŠŠè¯„ä¼°ç»“æœä¿å­˜æˆè¡¨æ ¼ï¼Œæ–¹ä¾¿åç»­åˆ†æå’Œå¯¹æ¯”
    æ–‡ä»¶å†…å®¹ï¼šæ¯è¡Œæ˜¯ä¸€ä¸ªé—®é¢˜çš„è¯„ä¼°ç»“æœï¼ŒåŒ…å«æ‰€æœ‰æŒ‡æ ‡
    """
    if not rows:
        return
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    
    # è·å–è¡¨å¤´ï¼ˆæ‰€æœ‰å­—æ®µåï¼‰
    headers = list(rows[0].keys())
    
    # å†™å…¥CSVæ–‡ä»¶
    with open(out_path, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()  # å†™å…¥è¡¨å¤´
        writer.writerows(rows)  # å†™å…¥æ‰€æœ‰æ•°æ®è¡Œ


def summarize(rows: List[Dict[str, object]]) -> Tuple[float, float]:
    """
    ğŸ“ˆ è®¡ç®—æ•´ä½“è¯„ä¼°æŒ‡æ ‡çš„å¹³å‡å€¼
    
    è¾“å…¥ï¼šæ‰€æœ‰é—®é¢˜çš„è¯„ä¼°ç»“æœåˆ—è¡¨
    è¾“å‡ºï¼š(å¹³å‡Hit@K, å¹³å‡å…³é”®è¯è¦†ç›–ç‡)
    
    ä½œç”¨ï¼šä»å¤šä¸ªé—®é¢˜çš„ç»“æœä¸­ï¼Œè®¡ç®—æ•´ä½“è¡¨ç°
    ä¾‹å¦‚ï¼š3ä¸ªé—®é¢˜ï¼ŒHit@Kåˆ†åˆ«æ˜¯[1,0,1]ï¼Œå¹³å‡å°±æ˜¯0.67
    """
    if not rows:
        return 0.0, 0.0
    
    # è®¡ç®—å¹³å‡Hit@Kï¼ˆæˆåŠŸçš„é—®é¢˜æ•° / æ€»é—®é¢˜æ•°ï¼‰
    avg_hit = sum(int(r["hit_at_k"]) for r in rows) / len(rows)
    
    # è®¡ç®—å¹³å‡å…³é”®è¯è¦†ç›–ç‡
    avg_cov = sum(float(r["keyword_coverage"]) for r in rows) / len(rows)
    
    return avg_hit, avg_cov


def build_argparser() -> argparse.ArgumentParser:
    """
    ğŸ”§ æ„å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    
    æ”¯æŒçš„å‚æ•°ï¼š
    - --k: æ£€ç´¢å‰Kä¸ªç‰‡æ®µï¼ˆé»˜è®¤ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼ï¼‰
    - --rerank: æ˜¯å¦å¯ç”¨é‡æ’ï¼ˆæå‡ç²¾åº¦ä½†é€Ÿåº¦æ…¢ï¼‰
    - --export: å¯¼å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    p = argparse.ArgumentParser(description="æ£€ç´¢ä¾§è¯„ä¼°ï¼šHit@K & å…³é”®è¯è¦†ç›–ç‡ & å¼•ç”¨å¯ä¿¡åº¦")
    p.add_argument("--k", dest="top_k", type=int, default=None, 
                   help="Top-Kï¼ˆé»˜è®¤å–é…ç½®SIMILARITY_TOP_Kï¼‰")
    p.add_argument("--rerank", action="store_true", 
                   help="æ˜¯å¦å¯ç”¨äº¤å‰ç¼–ç å™¨é‡æ’ï¼ˆæå‡ç²¾åº¦ä½†é€Ÿåº¦æ…¢ï¼‰")
    p.add_argument("--export", type=str, default=None, 
                   help="å¯¼å‡ºCSVè·¯å¾„ï¼Œå¦‚ data/eval_results.csv")
    p.add_argument("--repeats", type=int, default=1,
                   help="æ¯ä¸ªé—®é¢˜é‡å¤è¯„ä¼°æ¬¡æ•°ï¼ˆé»˜è®¤1ï¼Œç”¨äºç¨³å®šæ€§å¿«æµ‹ï¼‰")
    # HyDE/æ··åˆæ£€ç´¢
    p.add_argument("--hyde", action="store_true", help="ä½¿ç”¨HyDEå‡è®¾ç­”æ¡ˆè¿›è¡Œæ£€ç´¢")
    p.add_argument("--hybrid", action="store_true", help="åŸå§‹+HyDEæ£€ç´¢ç»“æœèåˆ")
    return p


def main() -> None:
    """
    ğŸš€ ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„è¯„ä¼°æµç¨‹
    
    æ‰§è¡Œæ­¥éª¤ï¼š
    1. è§£æå‘½ä»¤è¡Œå‚æ•°
    2. åŠ è½½é…ç½®å’Œæµ‹è¯•é—®é¢˜
    3. åˆå§‹åŒ–æ£€ç´¢æœåŠ¡å¹¶åŠ è½½ç´¢å¼•
    4. å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜æ‰§è¡Œè¯„ä¼°
    5. è®¡ç®—æ•´ä½“æŒ‡æ ‡å¹¶è¾“å‡ºç»“æœ
    6. å¯é€‰ï¼šå¯¼å‡ºCSVæ–‡ä»¶
    """
    print("ğŸš€ å¼€å§‹æ‰§è¡Œè¯„ä¼°è„šæœ¬...")
    
    # æ­¥éª¤1ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°
    args = build_argparser().parse_args()
    print(f"ğŸ“‹ è§£æå‚æ•°: {args}")

    # æ­¥éª¤2ï¼šåŠ è½½é…ç½®
    cfg = Config()
    print(f"âš™ï¸ é…ç½®åŠ è½½å®Œæˆï¼Œæµ‹è¯•é—®é¢˜æ•°é‡: {len(cfg.TEST_QUESTIONS)}")
    
    # æ­¥éª¤3ï¼šåˆå§‹åŒ–æ£€ç´¢æœåŠ¡
    svc = RetrievalService(cfg)
    hyde_svc = HyDERetriever(cfg=cfg, retrieval=svc)
    print("ğŸ”„ æ­£åœ¨åŠ è½½ç´¢å¼•ä¸åµŒå…¥æ¨¡å‹...")
    svc.load()
    print("âœ… ç´¢å¼•åŠ è½½å®Œæˆ")

    # æ­¥éª¤4ï¼šè®¾ç½®è¯„ä¼°å‚æ•°
    k = int(args.top_k or cfg.SIMILARITY_TOP_K)
    enable_rerank = bool(args.rerank)
    print(f"\nğŸ“Š è¯„ä¼°å‚æ•°: K={k}, rerank={enable_rerank}")

    # æ­¥éª¤5ï¼šå¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜æ‰§è¡Œè¯„ä¼°
    rows: List[Dict[str, object]] = []
    print(f"\nğŸ” å¼€å§‹è¯„ä¼° {len(cfg.TEST_QUESTIONS)} ä¸ªé—®é¢˜...")
    
    for i, item in enumerate(cfg.TEST_QUESTIONS):
        q = item.get("question", "").strip()
        expected_keywords = item.get("expected_keywords", []) or []
        
        print(f"\nğŸ“ [{i+1}] é—®é¢˜: {q}")
        print(f"ğŸ¯ æœŸæœ›å…³é”®è¯: {expected_keywords}")
        
        # æ‰§è¡Œè¯„ä¼°ï¼ˆæ”¯æŒé‡å¤ä»¥åšç¨³å®šæ€§å¿«æµ‹ï¼‰
        repeat = max(1, int(args.repeats))
        recs: List[Dict[str, object]] = []
        for _ in range(repeat):
            recs.append(
                evaluate_single_question(
                    svc=svc,
                    hyde=hyde_svc,
                    question=q,
                    expected_keywords=expected_keywords,
                    top_k=k,
                    enable_rerank=enable_rerank,
                    use_hyde=bool(args.hyde),
                    use_hybrid=bool(args.hybrid),
                )
            )

        # èšåˆç»Ÿè®¡
        hits = [int(r["hit_at_k"]) for r in recs]
        covs = [float(r["keyword_coverage"]) for r in recs]
        cit_in = [int(r["citation_in_topk"]) for r in recs]
        cit_rank = [r["citation_best_rank"] or 0 for r in recs]

        agg = dict(recs[-1])
        agg.update({
            "hit_at_k_mean": round(sum(hits)/len(hits), 4),
            "hit_at_k_std": round(statistics.pstdev(hits) if len(hits) > 1 else 0.0, 4),
            "keyword_coverage_mean": round(sum(covs)/len(covs), 4),
            "keyword_coverage_std": round(statistics.pstdev(covs) if len(covs) > 1 else 0.0, 4),
            "citation_in_topk_mean": round(sum(cit_in)/len(cit_in), 4),
            "citation_best_rank_min": (min([c for c in cit_rank if c > 0]) if any(c > 0 for c in cit_rank) else None),
            "repeats": repeat,
        })
        rows.append(agg)

        # æ˜¾ç¤ºç»“æœï¼ˆä»¥èšåˆåçš„æœ€åä¸€æ¬¡è®°å½•ä¸ºä»£è¡¨ï¼‰
        print(f"ğŸ“ˆ ç»“æœ: hit@{k}={agg['hit_at_k']} | å…³é”®è¯è¦†ç›–ç‡={agg['keyword_coverage']:.3f} ({agg['num_present']}/{agg['num_expected']})")
        if agg["present_keywords"]:
            print(f"âœ… å‘½ä¸­çš„å…³é”®è¯: {agg['present_keywords']}")
        else:
            print("âŒ æœªå‘½ä¸­ä»»ä½•å…³é”®è¯")

    # æ­¥éª¤6ï¼šè®¡ç®—å¹¶æ˜¾ç¤ºæ•´ä½“æŒ‡æ ‡
    avg_hit, avg_cov = summarize(rows)
    print("\n" + "="*50)
    print("ğŸ“Š æ•´ä½“è¯„ä¼°ç»“æœ")
    print("="*50)
    print(f"ğŸ¯ å¹³å‡ Hit@{k}: {avg_hit:.3f} ({avg_hit*100:.1f}%)")
    print(f"ğŸ“ˆ å¹³å‡å…³é”®è¯è¦†ç›–ç‡: {avg_cov:.3f} ({avg_cov*100:.1f}%)")
    
    # æ­¥éª¤7ï¼šå¯¼å‡ºCSVï¼ˆå¦‚æœæŒ‡å®šäº†è·¯å¾„ï¼‰
    if args.export:
        export_csv(rows, args.export)
        print(f"\nğŸ’¾ å·²å¯¼å‡ºCSV: {args.export}")
        print("ğŸ’¡ å¯ä»¥ç”¨Excelæˆ–å…¶ä»–å·¥å…·æ‰“å¼€æŸ¥çœ‹è¯¦ç»†ç»“æœ")


if __name__ == "__main__":
    main()


